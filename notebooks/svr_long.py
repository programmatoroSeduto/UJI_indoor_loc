# -*- coding: utf-8 -*-
"""SVR_long.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oXtYCJz3gV_-XS246AjhD-5mxUiW4mmV
"""

# frameworks vari
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import pandas as pd

# toy samples
import sklearn.datasets as datasets

# sciKitLearn
import sklearn.model_selection as model_selection
import sklearn.preprocessing as preprocessing
import sklearn.svm as svm
import sklearn.neighbors as neighbors
import sklearn.metrics as metrics

# path handler
from pathlib import Path 

# per il salvataggio del modello su file
import pickle as pk

from google.colab import drive
drive.mount('/content/drive')

training_set_path = '/content/drive/MyDrive/UJI_indoor_loc/UJI_indoor_loc/'
test_set_path = '/content/drive/MyDrive/UJI_indoor_loc/UJI_indoor_loc/'
save_path = '/content/drive/MyDrive/UJI_indoor_loc/UJI_indoor_loc/'

# load dataset
Ds_tr = pd.read_csv( save_path + 'myTrainingSet.csv' ).to_numpy( )
Ds_tt = pd.read_csv( save_path + 'myTestSet.csv' ).to_numpy( )

print( type( Ds_tr ) )
print( Ds_tr.shape[0] )
print( Ds_tr )

# separazione del dataset in due parti
X_tr = Ds_tr[:, 0:520]
y_tr = Ds_tr[:, [520, 521]]
X_tt = Ds_tt[:, 0:520]
y_tt = Ds_tt[:, [520, 521]]

# normalizzazione
scaleX = preprocessing.MinMaxScaler( feature_range=(0, 1) )
scaleX.fit( np.row_stack((X_tr, X_tt)) )

X_tr = scaleX.transform( X_tr )
X_tt = scaleX.transform( X_tt )

svr_param = {
	'C'       : np.logspace( -4, 3, 15 ),
	'gamma'   : np.logspace( -4, 3, 15 ),
	'epsilon' : [0, 0.01]
}

# Model Selection per SVR -- longitudine
H_long = model_selection.GridSearchCV( 
	estimator  = svm.SVR( kernel='rbf' ),
	param_grid = svr_param,
	scoring    = 'neg_mean_absolute_error',
	cv         = 2,
	verbose    = 2
).fit( X_tr, y_tr[:, 0] )

# parametri del modello
print( "--- Best Params for Longitude ---" )
print( "C : ", H_long.best_params_['C'] )
# print( "kernel : ", H_long.best_params_['kernel'] )
print( "gamma : ", H_long.best_params_['gamma'] )
print( "epsilon : ", H_long.best_params_['epsilon'] )
print( "---" )

# salvataggio dei coefficienti per la longitudine
# pd.DataFrame( H_long ).to_csv( save_path + "params_train_long.csv" )

# SVR su longitudine
lm_long = svm.SVR( 
  C = H_long.best_params_['C'],
	#kernel = H_long.best_params_['kernel'],
	kernel = 'rbf',
	gamma = H_long.best_params_['gamma'],
	epsilon = H_long.best_params_['epsilon'] 
).fit( X_tr, y_tr[:, 0] )
print( "--- Score Longitudine --- " )
print( "Score sul training set: ", lm_long.score( X_tr, y_tr[:, 0] ) )
# print( "Score sul test set: ", lm_long.score( X_tt, y_tt[:, 0] ) )
print( "---" )

with open( save_path + 'LM_long_data.sav', 'wb' ) as fil:
  pk.dump( lm_long, fil )

# test dati longitudine
import pickle as pk

LM_long = []
with open( save_path + 'LM_long_data.sav', 'rb' ) as fil:
  LM_long = pk.load( fil )

ym_long = lm_long.predict( X_tt )
# ym_lat = lm_lat.predict( X_tt )

# mean square error
mse_long = metrics.mean_squared_error( y_tt[:, 0], ym_long, squared=False )
# mse_lat = metrics.mean_squared_error( y_tt[:, 1], ym_lat, squared=False )

print( "MSE longitude: ", mse_long )
# print( "MSE latitude: ", mse_lat )

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
mpl.rcParams['figure.figsize'] = (15, 6)

fig1, ax1 = plt.subplots( )

fig1.suptitle( "Training Set structure" )

ax1.grid( True )
ax1.plot( Ds_tr[:, 520], Ds_tr[:, 521], 'x' ) # longitudine - latitudine

plt.show( )